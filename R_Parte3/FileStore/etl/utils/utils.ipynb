{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP5Ifzd0rGK+A9cgnmMHezg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"_mKyF1EQL2OT"},"outputs":[],"source":["import logging\n","from pyspark.sql import SparkSession"]},{"cell_type":"code","source":["# Iniciar sesión de Spark global\n","spark = SparkSession.builder.appName(\"CreditRisk\").getOrCreate()"],"metadata":{"id":"97E_dRCUMr4D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Función de lectura de archivo csv\n","\n","def upload_csv(ruta):\n","    \"\"\"Función para leer archivos CSV en Spark con manejo de errores.\"\"\"\n","    try:\n","        df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(ruta)\n","        logging.info(f\"Archivo {ruta} cargado correctamente con {df.count()} registros.\")\n","        return df\n","    except Exception as e:\n","        logging.error(f\"Error al cargar {ruta}: {str(e)}\")\n","        return None"],"metadata":{"id":"BA2_KChvM0Nc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Función de carga de datos\n","def load_parquet(path):\n","    \"\"\"Función para cargar archivos Parquet con manejo de errores.\"\"\"\n","    try:\n","        df = spark.read.parquet(path)\n","        logging.info(f\"Archivo {path} cargado con {df.count()} registros.\")\n","        return df\n","    except Exception as e:\n","        logging.error(f\"Error al cargar {path}: {str(e)}\")\n","        return None"],"metadata":{"id":"sFo7S8GsMt0u"},"execution_count":null,"outputs":[]}]}